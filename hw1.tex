%{
\documentclass[11pt, twoside]{article}   	% use "amsart" instead of "article" for AMSLaTeX format
\usepackage{geometry}                		% See geometry.pdf to learn the layout options. There are lots.
\geometry{letterpaper}                   		% ... or a4paper or a5paper or ... 
%\geometry{landscape}                		% Activate for for rotated page geometry
\usepackage[parfill]{parskip}    		% Activate to begin paragraphs with an empty line rather than an indent
\usepackage{graphicx}				% Use pdf, png, jpg, or epsÂ§ with pdflatex; use eps in DVI mode
								% TeX will automatically convert eps --> pdf in pdflatex	
\usepackage{amssymb}
\usepackage{color}
\usepackage{matlab-prettifier}
\usepackage{verbatim}
\usepackage{fancyvrb}
\usepackage{multicol}
\usepackage{bm}
\lstset{style=Matlab-editor,basicstyle=\ttfamily}

\sloppy
\definecolor{lightgray}{gray}{0.5}
\newenvironment{matlab}{\comment}{\endcomment}
\newenvironment{matlabv}{\lstlisting}{\endlstlisting}	


\title{Homework \# 1}
\author{Cody W. Eilar}
%\date{}							% Activate to display a given date or no date

\begin{document}
\maketitle
\section{Introduction} 
This paper investigates support vector machines (SVM) for both classification
 of simple datasets. It explores these methods by leveraging
the \textbf{MATLAB} bindings for \textbf{LIBSVM}. Here, we use simple datasets
so that we can get a feel for how well an SVM works so that we can then 
apply it to more complicated and useful datasets. 

\begin{matlab}
%}
close all; 
clear all;
% Set the random seed for reproducibility 
train_seed = rng(1); 
test_seed = rng(2); 

fid = fopen('tmp/computer.tex', 'w'); 
fprintf(fid, computer); 
fclose(fid); 

fid = fopen('tmp/matlabver.tex', 'w'); 
a = ver('matlab'); 
fprintf(fid, [a.Name ' version ' a.Version]); 
fclose(fid); 
%{
\end{matlab}

\section{Theory}
The theory behind \textit{SVMs} is fairly simple even though they are designed
to solve complicated problems. At the core, \textit{SVMs} are linear machines
which makes them easy to analyze and information can be more easily 
interpreted because of their linear nature. Though they are linear machines,
a trick and be used to exploit seemingly non-linear behavior using the kernel trick. 
I do not exploit this trick in this paper because we only want to investigate
\textit{SVMs} at their most primitive state. Ultimately, we solve Equation \ref{eq:basic} 

\begin{equation}
\hat{y}= \mathbf{w}^T\mathbf{x} + b 
\label{eq:basic}
\end{equation}

with the following constraints

\begin{equation}
\mathbf{w} = \sum\limits_{n=1}^{N} \alpha_n y_n\mathbf{x}_n
\label{eq:c1}
\end{equation}

\begin{equation}
C - \alpha_n -\mu_n = 0
\label{eq:c2}
\end{equation}

\begin{equation}
\sum\limits_{n=1}^{N} \alpha_n y_n = 0
\label{eq:c3}
\end{equation}

\begin{equation}
\mu_n \xi_n = 0
\label{eq:c4}
\end{equation}

\begin{equation}
\alpha_n(y_n(\mathbf{w}^T\mathbf{x}_n + b) - 1 + \xi_n) = 0
\label{eq:c5}
\end{equation}

\begin{equation}
\alpha_n \geq 0, \mu_n \geq 0, \xi_n \geq 0
\label{eq:c6}
\end{equation}

All the constraints listed above are known as the \textit{KKT} conditions and are important
constraints for solving support vector machines. 

\section{Results \& Experiments}
 In this section we set up the experiments necessary to see how well
 the support vector machine works. This section performs the experiments
 by first setting up the data necessary with which to test, and then 
 running the support vector machine algorithms using \textbf{LIBSVM}
  to test their performance on the data. In order to do this, 
we need to first create some data. For the simple linear case, we can create
four Gaussian distributions and plot them. Also, for reproducibility 
we note that the code was run using \input{tmp/computer} running
 \input{tmp/matlabver} . That said, we can create four Gaussians
with the following code and classify them as either being $+1$ or $-1$. 

\begin{matlab}
%}

fid = fopen('tmp/computer.tex', 'w'); 
fprintf(fid, computer); 
fclose(fid); 
%{
\end{matlab}

\begin{lstlisting}
%}
sigma = 0.2; 
N = 10; 
rng(train_seed)
[X, Y] = plot2d(sigma, N);
title('Four Gaussian distributions of points'); 
saveas(gcf,'tmp/gaussian.eps','epsc')
%{
\end{lstlisting}  


\begin{figure}[h]
\centering
\includegraphics[width=4in]{tmp/gaussian.eps}
\caption{Gaussian plot}
\label{fig:gaus} 
\end{figure}

From Figure  \ref{fig:gaus}, we can see that there is a natural separation between the two labels. 
The code shows that the first half of the  variable is negative 1, and the second half is positive 1. 
We now have a simple linear problem to classify. We can further say that the classes are almost
linearly separable, but there is some overlap. So even if we end up with a great classifier, there
will still be points that are not properly classified. 


\subsection{Construction of a Classifier with the Model Parameters}
The next step is to now classify the data using \textbf{LIBSVM}. This is done by calling \texttt{svmtrain}.
 Typically, we would want to break up the training and testing data, but since 
this is just a simple example, we will be using the training data for the testing as well. The following code 
trains the model: 
\begin{lstlisting}
%}
delete 'tmp/svmtrain.txt'
diary 'tmp/svmtrain.txt'
model = svmtrain(Y', X, '-s 0 -t 0 -c 100');
diary off; 
%{
\end{lstlisting}

\color{lightgray}

\VerbatimInput{tmp/svmtrain.txt}

\color{black}

The parameters mean the following: 
\begin{itemize}
\item -s 0 - This defines the kernel type
\item -t 0 - This specifies the kernel type, 0 is for a linear kernel
\item -c 100 - This specifies the cost, here the cost is 100
\end{itemize}

Now that we have the model, we need to see how well we can classify
the data using \texttt{svmpredict}. 
\begin{lstlisting}
%}
delete 'tmp/svmpredict.txt'
diary 'tmp/svmpredict.txt'
[predicted_label, accuracy, prob_estimates] = svmpredict(Y', X, model); 
diary off
%{
\end{lstlisting}

The output from running \texttt{svmpredict} is the following: 
\color{lightgray}
\VerbatimInput{tmp/svmpredict.txt}
\color{black}

It is obvious from these results that we can predict the data pretty well. 
but what happens if we compare this to a different method? Will we get
similar results? An easy test is to classify the data using \textbf{MATLAB}
's function \texttt{lsqlin} with the same parameters that we used 
for the support vector machine. 

\subsection{Graphical Representation of an SVM}

Before we compare though, let us start by plotting the shattering
hyperplane along with circling the support vectors. 
\begin{matlab}
%}
w = model.SVs' * model.sv_coef;
b = -model.rho;
if model.Label(1) == -1
  w = -w;
  b = -b;
end
hold on 
sv = full(model.SVs);
plot(sv(:,1),sv(:,2),'kO', 'MarkerSize', 10);

y_hat = sign(w'*X' + b);

plot_x = linspace(min(X(:,1)), max(X(:,1)), 30);

plot_y = (-1/w(2))*(w(1)*plot_x + b);
d_plus = plot_y + 1/norm(w); 
d_minus = plot_y - 1/norm(w);
plot(plot_x, d_plus, 'r--'); 
hold on; 
plot(plot_x, d_minus, 'b--'); 
plot(plot_x, plot_y, 'k-', 'LineWidth', 1)
title('Plot of shattering hyperplane and support vectors'); 
legend('+1', '-1', 'Support Vectors', 'margin', '-margin', 'Hyperplane', 'Location', 'Northwest')
saveas(gcf,'tmp/svmplot.eps','epsc')

%{
\end{matlab}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{tmp/svmplot.eps}
\caption{Plot of shattering hyperplane and support vectors}
\label{fig:svm} 
\end{figure}

\begin{lstlisting}
%}
delete 'tmp/lsqlin.txt'
diary 'tmp/lsqlin.txt'
z = lsqlin(X, Y)  
diary off
%{
\end{lstlisting}

\color{lightgray}
\VerbatimInput{tmp/lsqlin.txt}
\color{black}

As with the SVM, the whole point of the least squares classifier
is to solve the equation: 
\begin{equation}
f(x) = \hat{y}_n = \bm{w}^T\bm{x}_n + b
\end{equation}

So now we can plot the least squares result and compare it to the SVM
result. The results of the figure are show in Figure \ref{fig:lsq}. 
\begin{lstlisting}
%}
y_lsq = -(z(1)/z(2))*plot_x; 
plot(plot_x, y_lsq); 
legend('+1', '-1', 'Support Vectors', 'margin', '-margin', 'Hyperplane',...
   'Least Squares', 'Location', 'Northwest')
saveas(gcf,'tmp/lsqplot.eps','epsc')
%{
\end{lstlisting}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{tmp/lsqplot.eps}
\caption{Plot of shattering hyperplane, support vectors and the least
squares solution}
\label{fig:lsq} 
\end{figure}

We can see from Figure \ref{fig:lsq} that almost all the same points are 
classified except for two: it properly classifies one $-1$ value and 
misclassifies one $+1$ value. 

\subsection{Estimating The Structural Risk}

The goal of this section is plot the structural risk ($R(\alpha)$) and 
the empirical risk ($R_{emp}(\alpha)$). The function that is used for
generating the points is as follows (this function was given to us 
in the homework): 

\lstinputlisting{DataGenerator.m}

Given that function we then do the following
\begin{itemize}
\item Set C to a value: 
\begin{lstlisting}
%}
C = 100; 
%{
\end{lstlisting}
\item Generate a set of 100 data, which will have a noise standard
deviation equal to $\sigma/2$. The data generator function below generates
data that is 10 dimensions. There are eight points describing a cube 
of dimension $\sigma$, four points are at one side of the planed described by
Equation \ref{eq:cube}. Here the $b=0$, at a distance $\sigma/2$ and they are
labelled with $-1$. The other four are on the other side of the plane and are labelled
as $+1$. 

\begin{equation}
\Pi \equiv \mathbf{w}^T\mathbf{x} + b , \mathbf{w}_i = 1/\sqrt(10)
\label{eq:cube}
\end{equation}
 
\begin{lstlisting}
%}
sigma = 0.2; 
N = 100; 
[X1, Y1] = DataGenerator(N, sigma/2, train_seed); 
%{
\end{lstlisting}  

\item Train an SVM and compute its empirical error
\begin{lstlisting}
%}
delete 'tmp/train_10d.txt'
diary 'tmp/train_10d.txt'
params = sprintf('-s 0 -t 0 -c %d', C); 
m1 =  svmtrain(Y1, X1, params);
diary off; 
%{
\end{lstlisting} 

\color{lightgray}
\VerbatimInput{tmp/train_10d.txt}
\color{black}

Now that we have trained the svm, we need to compute the empirical error (also known as the
empirical risk). This is defined below in Equation \ref{eq:emp_risk}. 

\begin{equation}
R_{emp}(\alpha) = \frac{1}{2l} \sum\limits_{i=1}^l|y_i - f(x_i, \alpha)|
\label{eq:emp_risk}
\end{equation}

In Equation \ref{eq:emp_risk},
\begin{itemize}
\item $l$ - The number of observations
\item $y_i$ - is the the truth, in the case of the code this represents 
\texttt{Y1}
\item $\alpha$ - These are the support vector coefficients from the
training. 
\item $x_i$ - These are the observations, in the case of the code, this is
related to variable \texttt{X1}. 
\end{itemize}

So we can now perform the calculation. Recall that the formula for
$\mathbf{w}^T$ is: 

\begin{equation}
\mathbf{w} = \mathbf{X}\mathbf{Y}\mathbf{\alpha}^T
\label{eq:wt}
\end{equation}


Equation \ref{eq:wt} is just another way of writing \ref{eq:wtsum}. 
\begin{equation}
\mathbf{w} = \sum\limits_{n=1}^N \alpha_n y_n \mathbf{x}_n
\label{eq:wtsum}
\end{equation}


\begin{lstlisting}
%}
l = size(Y1,1); 
loss = 0; 
%Get W
y = diag(Y1(m1.sv_indices));
x = X1(m1.sv_indices, :);
alpha = m1.sv_coef;
w = alpha'*y*x;
b = -m1.rho; 
y_hat = sign(w*x' + b);

% Only certain observations contain non-zero values, hence we only index
% into the vectors calculated from training. 
for i = 1:size(m1.sv_indices,1); 
  
   loss = loss + abs(Y1(m1.sv_indices(i)) - y_hat(i));
end
fid = fopen('tmp/loss.tex', 'w');
fprintf(fid, '%f', 1/(2*l)*loss); 
fclose(fid);
%{
\end{lstlisting}
The loss is then calculated to be \input{tmp/loss}. 

\item We now need to generate another set of data (using a different random 
 seed of course). 

\begin{lstlisting}
%}

[X2, Y2] = DataGenerator(N, sigma/2, test_seed);
[predicted_label, accuracy, prob_estimates] = svmpredict(Y2, X2, m1); 
fid = fopen('tmp/accuracy_31.tex', 'w');
fprintf(fid, '%f', accuracy(1)); 
fclose(fid); 
%{
\end{lstlisting}

We can see now that we have a \input{tmp/accuracy_31.tex}\% accuracy. 

Using a similar method as the above, we want calculate the empirical error
and the test error for different values of C and plot the values
logarithmically. 
\begin{lstlisting}
%}
%%
c_range = logspace(-1.5, 5, 100);

r_emp = zeros(size(c_range)); 
r_s = zeros(size(c_range)); 
nu = 10^(-3);
N=100;
sigma = .2;
test_err = zeros(size(c_range)); 
train_err = zeros(size(c_range)); 
[X1, Y1] = DataGenerator(N, sigma/2, rng('default')); 
[X2, Y2] = DataGenerator(N, sigma/2, rng('default')); 

for i = 1:size(c_range,2)
   params = sprintf('-s 0 -t 0 -c %d -q', c_range(i)); 
   m1 =  svmtrain(Y1, X1, params);
  [~, err, ~] = svmpredict(Y1, X1, m1, '-q'); 
  % train_err(i) = EmpiricalRisk(X1, Y1, m1); 
  train_err(i) = err(2); 
  [~, err, ~] = svmpredict(Y2, X2, m1, '-q');
  %test_err(i) = EmpiricalRisk(X2, Y2, m1); 
  test_err(i)  = err(2); 
end

figure; 
semilogx(c_range, test_err);
hold on; 
semilogx(c_range, train_err); 
hold on ;
semilogx(c_range, abs(test_err-train_err)); 
hold off; 
legend('Testing Error', 'Training Error', 'Testing - Training'); 
title('Plot of training and testing errors for different values of C'); 
xlabel 'Values of C'
ylabel 'Mean Square Error'
saveas(gcf,'tmp/error_plot.eps','epsc')

%{
\end{lstlisting}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{tmp/error_plot.eps}
\caption{Plot of training and testing errors for different values of C}
\label{fig:c_errors} 
\end{figure}

\item From Figure \ref{fig:c_errors} we can see that the training error is
always lower than the testing error. This makes sense because the test error
is defined by the empirical plus the Vapnik Chervonenkis confidence. Therefore we
would expect the training to be lower than the testing error because of the mathematical 
definition of the expected risk. This is shown in Equation \ref{eq:exp_risk}. 

\begin{equation}
R(\alpha) \leq R_{emp}(\alpha) + \sqrt{(\frac{h(log(2l/h)+1) -log(\eta/4)}{l})}
\label{eq:exp_risk}
\end{equation}

\item Now we want to observe if, instead of varying C, we vary the number
of data from $N=10$ to $N=100$, holding $\sigma = 0.3$ and $C=1$.

\begin{lstlisting}
%}
%%
n_range = 1:1:500; 
sigma = .2; 
C = .01; 
train_err = zeros(size(n_range)); 
test_err = zeros(size(n_range)); 

for i = 1:size(n_range, 2)
   
   [train_x, train_y] = DataGenerator(n_range(i), sigma, train_seed);

   [test_x, test_y] = DataGenerator(n_range(i), sigma, test_seed);
   
   params = sprintf('-s 0 -t 0 -c %d -q', C); 
   model =  svmtrain(train_y, train_x, params);
   [~, err, ~] = svmpredict(train_y, train_x, model, '-q'); 
   train_err(i) = err(2); 
   [~, err, ~] = svmpredict(test_y, test_x, model, '-q');
   test_err(i) = err(2); 
end

figure; 
plot(n_range, train_err, 'x'); 
hold on; 
plot(n_range, test_err, 'o'); 
title('Error vs the number of data samples.'); 
legend('Training Error', 'Testing Error'); 
xlabel('Number of samples'); 
ylabel('Error'); 
saveas(gcf,'tmp/sample_error.eps','epsc')


%{
\end{lstlisting}

\begin{figure}[h]
\centering
\includegraphics[width=4in]{tmp/sample_error.eps}
\caption{Plot of training and testing errors for different values of N}
\label{fig:n_errors} 
\end{figure}

We can see in Figure \ref{fig:n_errors} that as we increase the number of
samples, that the error for the training set starts very low, and then begins to rise. The testing
error does the exact opposite where the error is high to begin with and then gets lower for higher
values of N. Eventually, both values meet together and seem to level off at the same error for higher values of N.
We would expect to see this because we
get more data with which to average and shatter the points with a more
accurate hyperplane. The learning procedure seems consistent because we would expect that if we train
and test on 
\end{itemize}

\section{Conclusion}
From this brief study, we can see that using the package \textit{LIBSVM} we can accurately classify multidimensional 
data consistently and accurately. Even though the use cases in this scenario are contrived and fairly trivial, SVMs
have proven to be a useful tool in classification. In future works, we would like to see how well classification works on 
higher dimensional data using the \textit{kernel trick}.
\end{document}  
%}


